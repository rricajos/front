<!doctype html>
<html lang="es">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Gespropiedad Avatar Demo</title>
  <!-- Lucide Icons -->
  <script src="https://unpkg.com/lucide@latest/dist/umd/lucide.min.js"></script>
  <style>
    * {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      font-family: system-ui, -apple-system, sans-serif;
      background: linear-gradient(135deg, #0b0f14 0%, #1a1f2e 100%);
      color: #e6edf3;
      min-height: 100vh;
      display: flex;
      align-items: center;
      justify-content: center;
      padding: 16px;
    }

    .stage {
      width: 100%;
      max-width: 980px;
      background: #0f1621;
      border: 1px solid #1f2a3a;
      border-radius: 20px;
      box-shadow: 0 10px 40px rgba(0, 0, 0, .35);
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 24px;
      padding: 28px;
      align-items: center;
    }

    /* Tablet */
    @media (max-width: 800px) {
      .stage {
        grid-template-columns: 1fr;
        gap: 20px;
        padding: 20px;
      }

      .avatar {
        order: 1;
      }

      .panel {
        order: 2;
      }
    }

    /* Mobile */
    @media (max-width: 480px) {
      body {
        padding: 8px;
      }

      .stage {
        border-radius: 16px;
        padding: 16px;
        gap: 16px;
      }

      .rive-wrap {
        width: 240px !important;
        height: 240px !important;
      }

      #riveCanvas {
        width: 220px !important;
        height: 220px !important;
      }

      .bubble {
        min-height: 80px !important;
        font-size: 16px !important;
      }

      .row {
        flex-direction: column;
      }

      button {
        width: 100%;
      }
    }

    .avatar {
      display: flex;
      justify-content: center;
      align-items: center;
      min-height: 280px;
    }

    .rive-wrap {
      width: 300px;
      height: 300px;
      display: grid;
      place-items: center;
      border-radius: 24px;
      background: radial-gradient(circle at 30% 30%, #1a2535, #0d121b 70%);
      border: 1px solid #223146;
      box-shadow:
        inset 0 0 0 1px rgba(255, 255, 255, 0.03),
        0 8px 32px rgba(0, 0, 0, 0.3);
      overflow: hidden;
    }

    #riveCanvas {
      width: 280px;
      height: 280px;
    }

    /* CSS Fallback Avatar */
    .css-avatar {
      display: none;
      place-items: center;
    }

    .head {
      width: 200px;
      height: 200px;
      border-radius: 50%;
      background: radial-gradient(circle at 30% 30%, #2b3b52, #111823 70%);
      position: relative;
      border: 1px solid #243247;
      animation: breathe 5.5s ease-in-out infinite;
    }

    @keyframes breathe {

      0%,
      100% {
        transform: translateY(0);
      }

      50% {
        transform: translateY(-2px);
      }
    }

    .eye {
      width: 22px;
      height: 22px;
      border-radius: 50%;
      background: #e6edf3;
      position: absolute;
      top: 70px;
      overflow: hidden;
    }

    .eye.left {
      left: 60px;
    }

    .eye.right {
      right: 60px;
    }

    .eye::after {
      content: "";
      position: absolute;
      inset: 0;
      background: #0f1621;
      transform: translateY(-120%);
      animation: blink 6s infinite;
    }

    @keyframes blink {

      0%,
      92%,
      100% {
        transform: translateY(-120%);
      }

      94%,
      96% {
        transform: translateY(0%);
      }
    }

    .pupil {
      width: 8px;
      height: 8px;
      border-radius: 50%;
      background: #0b0f14;
      position: absolute;
      top: 7px;
      left: 7px;
    }

    .mouth {
      width: 70px;
      height: 14px;
      background: #e6edf3;
      border-radius: 0 0 14px 14px;
      position: absolute;
      bottom: 55px;
      left: 50%;
      transform: translateX(-50%) scaleY(0.2);
      transform-origin: center top;
      transition: transform 40ms linear;
    }

    /* Panel */
    .panel {
      display: flex;
      flex-direction: column;
      gap: 14px;
    }

    .status {
      font-size: 13px;
      opacity: 0.8;
      display: flex;
      align-items: center;
      gap: 8px;
      flex-wrap: wrap;
    }

    .status-dot {
      width: 8px;
      height: 8px;
      border-radius: 50%;
      background: #666;
      flex-shrink: 0;
    }

    .status-dot.ok {
      background: #22c55e;
    }

    .status-dot.error {
      background: #ef4444;
    }

    .status-dot.loading {
      background: #eab308;
      animation: pulse 1s infinite;
    }

    @keyframes pulse {

      0%,
      100% {
        opacity: 1;
      }

      50% {
        opacity: 0.4;
      }
    }

    .debug {
      font-size: 10px;
      opacity: 0.7;
      font-family: 'SF Mono', Monaco, Consolas, monospace;
      max-height: 70px;
      overflow-y: auto;
      background: #080b10;
      padding: 10px;
      border-radius: 8px;
      white-space: pre-wrap;
      word-break: break-all;
      line-height: 1.4;
    }

    .bubble {
      background: #0b111b;
      border: 1px solid #1d2a3b;
      border-radius: 14px;
      padding: 16px 18px;
      min-height: 100px;
      max-height: 150px;
      overflow-y: auto;
      font-size: 17px;
      line-height: 1.45;
      flex-grow: 1;
    }

    @media (max-width: 480px) {
      .bubble {
        max-height: 100px;
      }
    }

    .row {
      display: flex;
      gap: 10px;
      flex-wrap: wrap;
    }

    button {
      background: #1b2a3d;
      color: #e6edf3;
      border: 1px solid #2a3c54;
      padding: 12px 16px;
      border-radius: 10px;
      cursor: pointer;
      font-weight: 600;
      font-size: 14px;
      transition: all 0.15s;
      flex: 1;
      min-width: 120px;
    }

    button:hover {
      background: #243a52;
      border-color: #3a5a7a;
    }

    button:active {
      transform: scale(0.97);
    }

    button i {
      width: 18px;
      height: 18px;
      flex-shrink: 0;
    }

    button.primary {
      background: #2563eb;
      border-color: #3b82f6;
    }

    button.primary:hover {
      background: #1d4ed8;
    }

    button:disabled {
      opacity: 0.5;
      cursor: not-allowed;
    }

    /* Fullscreen */
    .fullscreen-btn {
      position: absolute;
      top: 10px;
      right: 10px;
      background: rgba(0, 0, 0, 0.5);
      border: 1px solid rgba(255, 255, 255, 0.2);
      width: 40px;
      height: 40px;
      min-width: 40px;
      padding: 0;
      display: flex;
      align-items: center;
      justify-content: center;
      border-radius: 8px;
      z-index: 10;
    }

    .fullscreen-btn i {
      width: 20px;
      height: 20px;
    }

    .fullscreen-btn:hover {
      background: rgba(0, 0, 0, 0.7);
    }

    .avatar {
      position: relative;
    }

    /* Fullscreen mode */
    .rive-wrap.fullscreen {
      position: fixed !important;
      top: 0 !important;
      left: 0 !important;
      width: 100vw !important;
      height: 100vh !important;
      max-width: none !important;
      max-height: none !important;
      border-radius: 0 !important;
      z-index: 9999;
      background: #0b0f14;
    }

    .rive-wrap.fullscreen::before {
      content: "";
      position: absolute;
      bottom: 40px;
      right: 40px;
      width: 180px;
      height: 180px;
      opacity: 0.25;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 226.1 219.1'%3E%3Cdefs%3E%3ClinearGradient id='a' x1='56' y1='178.7' x2='56' y2='0' gradientUnits='userSpaceOnUse'%3E%3Cstop offset='0' stop-color='%231ca4af'/%3E%3Cstop offset='1' stop-color='%231c3768'/%3E%3C/linearGradient%3E%3ClinearGradient id='b' x1='139.2' y1='53.5' x2='232.6' y2='215.2' href='%23a'/%3E%3C/defs%3E%3Cpolygon fill='url(%23a)' points='0 0 73.6 111 26.2 178.7 65.6 178.7 111.9 109.9 41.8 0 0 0'/%3E%3Cpolygon fill='url(%23b)' points='194.6 45.6 150.2 111 226 219 186.7 219 111.9 109.9 152.9 45.6 194.6 45.6'/%3E%3C/svg%3E");
      background-repeat: no-repeat;
      background-position: center;
      background-size: contain;
      pointer-events: none;
      z-index: 0;
    }

    @media (max-width: 480px) {
      .rive-wrap.fullscreen::before {
        width: 100px;
        height: 100px;
        bottom: 20px;
        right: 20px;
      }
    }

    .rive-wrap.fullscreen #riveCanvas {
      position: relative;
      z-index: 1;
      width: 90vmin !important;
      height: 90vmin !important;
    }

    .rive-wrap.fullscreen .fullscreen-btn {
      top: 20px;
      right: 20px;
      width: 50px;
      height: 50px;
      background: rgba(0, 0, 0, 0.6);
      border: 1px solid rgba(255, 255, 255, 0.15);
    }

    .rive-wrap.fullscreen .fullscreen-btn i {
      width: 24px;
      height: 24px;
    }

    /* Voice selector */
    .voice-select {
      background: #1b2a3d;
      color: #e6edf3;
      border: 1px solid #2a3c54;
      padding: 10px 12px;
      border-radius: 8px;
      font-size: 13px;
      width: 100%;
      margin-top: 4px;
    }

    .voice-select:focus {
      outline: none;
      border-color: #3b82f6;
    }

    label {
      font-size: 12px;
      opacity: 0.7;
      display: block;
      margin-bottom: 4px;
    }

    .settings {
      background: #0a0e14;
      border-radius: 10px;
      padding: 12px;
      margin-top: 4px;
    }

    /* Overlay de inicio para desbloquear audio */
    .start-overlay {
      position: fixed;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      background: linear-gradient(135deg, #0b0f14 0%, #131a24 50%, #0d1117 100%);
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      z-index: 10000;
      gap: 24px;
    }

    .start-overlay.hidden {
      display: none;
    }

    .start-logo {
      width: 120px;
      height: auto;
      opacity: 0.9;
      margin-bottom: 8px;
    }

    .start-overlay h1 {
      font-size: 1.8rem;
      margin: 0;
      color: #fff;
      font-weight: 600;
      letter-spacing: -0.02em;
    }

    .start-overlay p {
      font-size: 1rem;
      opacity: 0.6;
      margin: 0;
      text-align: center;
      max-width: 280px;
    }

    .start-btn {
      background: linear-gradient(135deg, #1ca4af 0%, #1c3768 100%);
      color: white;
      border: none;
      padding: 18px 48px;
      font-size: 1.1rem;
      border-radius: 14px;
      cursor: pointer;
      font-weight: 600;
      transition: all 0.25s ease;
      box-shadow: 0 4px 24px rgba(28, 164, 175, 0.3);
      display: flex;
      align-items: center;
      gap: 12px;
      margin-top: 16px;
    }

    .start-btn:hover {
      transform: translateY(-2px);
      box-shadow: 0 8px 32px rgba(28, 164, 175, 0.4);
    }

    .start-btn:active {
      transform: translateY(0);
    }

    .start-btn i {
      width: 22px;
      height: 22px;
    }
  </style>
</head>

<body>
  <!-- Overlay para desbloquear audio -->
  <div class="start-overlay" id="startOverlay">
    <svg class="start-logo" viewBox="0 0 226.1 219.1" xmlns="http://www.w3.org/2000/svg">
      <defs>
        <linearGradient id="grad1" x1="56" y1="178.7" x2="56" y2="0" gradientUnits="userSpaceOnUse">
          <stop offset="0" stop-color="#1ca4af" />
          <stop offset="1" stop-color="#1c3768" />
        </linearGradient>
        <linearGradient id="grad2" x1="139.2" y1="53.5" x2="232.6" y2="215.2" gradientUnits="userSpaceOnUse">
          <stop offset="0" stop-color="#1ca4af" />
          <stop offset="1" stop-color="#1c3768" />
        </linearGradient>
      </defs>
      <polygon fill="url(#grad1)" points="0 0 73.6 111 26.2 178.7 65.6 178.7 111.9 109.9 41.8 0 0 0" />
      <polygon fill="url(#grad2)" points="194.6 45.6 150.2 111 226 219 186.7 219 111.9 109.9 152.9 45.6 194.6 45.6" />
    </svg>
    <h1>Asistente Virtual</h1>
    <p>Activa el audio para interactuar con el avatar</p>
    <button class="start-btn" id="startBtn">
      <i data-lucide="volume-2"></i>
      Comenzar
    </button>
  </div>
  <div class="stage">
    <div class="avatar">
      <!-- Rive Avatar -->
      <div class="rive-wrap" id="riveWrap">
        <button class="fullscreen-btn" id="fullscreenBtn" title="Pantalla completa"><i
            data-lucide="maximize-2"></i></button>
        <canvas id="riveCanvas" width="600" height="600"></canvas>
      </div>

      <!-- CSS Fallback -->
      <div class="css-avatar" id="cssAvatar">
        <div class="head">
          <div class="eye left">
            <div class="pupil"></div>
          </div>
          <div class="eye right">
            <div class="pupil"></div>
          </div>
          <div class="mouth" id="cssMouth"></div>
        </div>
      </div>
    </div>

    <div class="panel">
      <div class="status">
        <span class="status-dot loading" id="statusDot"></span>
        <span id="statusText">Inicializando...</span>
      </div>
      <div class="debug" id="debug"></div>
      <div class="bubble" id="bubble">Listo para recibir eventos del bot.</div>

      <div class="row">
        <button id="testTalk" class="primary"><i data-lucide="message-circle"></i> Test hablar</button>
        <button id="idleBtn"><i data-lucide="pause"></i> Idle</button>
      </div>

      <div class="settings">
        <label for="voiceSelect"><i data-lucide="mic"
            style="width:14px;height:14px;vertical-align:middle;margin-right:4px;"></i> Voz TTS:</label>
        <select id="voiceSelect" class="voice-select">
          <option value="">Cargando voces...</option>
        </select>
      </div>
    </div>
  </div>

  <script type="module">
    // ===========================================
    // CONFIGURACIÓN - Modifica estos valores
    // ===========================================
    const CONFIG = {
      // ElevenLabs (para generación en tiempo real - tiene delay)
      ELEVENLABS_API_KEY: "sk_ed00c8630aeb0240abba435c3f0a4afcd6794a79c0d1aba6",  // Tu API key de ElevenLabs
      ELEVENLABS_VOICE_ID: "uU1QvfOppdkePeLtG9pI",  // Lucia - español España
      ELEVENLABS_MODEL: "eleven_multilingual_v2",

      // WebSocket backend
      BACKEND_HOST: "hogar-avatar-api.conexiatec.com",

      // Rive
      RIVE_FILE: "./avatar.riv",
      STATE_MACHINE: "State Machine",

      // TTS Fallback (usar voz del navegador si no hay API key ni audio pregenerado)
      USE_BROWSER_TTS_FALLBACK: true,
    };



    // ===========================================
    // BANCO DE AUDIOS PREGENERADOS
    // Mapea textos exactos o IDs a archivos MP3
    // Prioridad: 1) Audio pregenerado, 2) ElevenLabs, 3) TTS navegador
    // ===========================================
    const AUDIO_BANK = {
      // Por ID (recomendado para llamadas desde Retell/backend)
      "intro": {
        text: "Os escucho perfectamente. Buenas noches a todos.\nY sí, confirmo, No duermo,\n– No pido vacaciones, y los lunes no me afectan. Pero prometo ser simpática igualmente.",
        audio: "./audio/intro.mp3"
      },
      "que_es": {
        text: "Vamos allá, Alejandro. Soy la nueva IA de Gestpropiedad. Estoy aquí para ayudar a tres grupos: a nuestros clientes, al equipo de atención telefónica y a vosotros, los asesores. Cuando el teléfono esté cerrado y el equipo haya terminado su jornada, yo seguiré atendiendo a los clientes para que nunca se queden sin respuesta.",
        audio: "./audio/que_es.mp3"
      },
      "aprendizaje": {
        text: "Esto es solo el principio. Hoy es, literalmente, mi primer día de vida. A partir de ahora iré aprendiendo cada día: de las consultas, de cómo trabajáis, de lo que necesitan los clientes y de toda la información que me ha dado el equipo. Cuanto más se me use, mejor podré ayudar y más partes del negocio podré cubrir. Prometo crecer rápido… y sin etapa de adolescencia rebelde.",
        audio: "./audio/aprendizaje.mp3"
      },
      "despedida": {
        text: "Exacto: todavía no tengo nombre. De momento soy “la IA de Gestpropiedad”, pero suena un poco frío y poco personal, ¿verdad? Como voy a trabajar para vosotros y con vosotros, quiero que seáis vosotros quienes elijáis mi nombre esta noche. Yo me despido aquí y le dejo a Alejandro que os explique las opciones. La próxima vez que aparezca, será ya con mi nombre oficial. Ha sido un placer saludaros por primera vez. Gracias… y nos vemos muy pronto. Ah, y tranquilos: ninguna de las opciones es “ChatPaco” ni “BotManolo”. De eso se ha asegurado todo el equipo. ¡Muchas gracias, equipo!",
        audio: "./audio/despedida.mp3"
      },

      // Añade más audios aquí:
      // "appointment_confirm": {
      //   text: "Tu cita ha sido confirmada para el día indicado.",
      //   audio: "./audio/appointment_confirm.mp3"
      // },
    };


    // ===========================================
    // También puedes mapear por texto exacto (alternativa)
    // ===========================================
    const AUDIO_BY_TEXT = {
      // "Texto exacto que dice el bot": "./audio/archivo.mp3",
    };
    // ===========================================

    // -----------------------------
    // Importar Rive desde CDN oficial
    // -----------------------------
    import RiveCanvas from "https://cdn.jsdelivr.net/npm/@rive-app/canvas@2.21.6/+esm";

    // -----------------------------
    // DOM
    // -----------------------------
    const $ = id => document.getElementById(id);
    const statusDot = $("statusDot");
    const statusText = $("statusText");
    const debugEl = $("debug");
    const bubbleEl = $("bubble");
    const riveWrap = $("riveWrap");
    const riveCanvas = $("riveCanvas");
    const cssAvatar = $("cssAvatar");
    const cssMouth = $("cssMouth");
    const voiceSelect = $("voiceSelect");

    function setStatus(text, state = "loading") {
      statusText.textContent = text;
      statusDot.className = "status-dot " + state;
    }

    function log(msg) {
      console.log("[Avatar]", msg);
      const time = new Date().toLocaleTimeString("es", { hour12: false });
      debugEl.textContent = `[${time}] ${msg}\n` + debugEl.textContent.slice(0, 500);
    }

    // -----------------------------
    // CSS Fallback
    // -----------------------------
    function cssSetMouthOpen(value) {
      const scale = 0.2 + (value * 0.8);
      cssMouth.style.transform = `translateX(-50%) scaleY(${scale})`;
    }

    // -----------------------------
    // Web Speech API - TTS
    // -----------------------------
    let synth = window.speechSynthesis;
    let voices = [];
    let selectedVoice = null;
    let currentUtterance = null;

    function loadVoices() {
      voices = synth.getVoices();

      // Filtrar voces en español preferentemente
      const spanishVoices = voices.filter(v => v.lang.startsWith('es'));
      const otherVoices = voices.filter(v => !v.lang.startsWith('es'));
      const sortedVoices = [...spanishVoices, ...otherVoices];

      voiceSelect.innerHTML = '';

      if (sortedVoices.length === 0) {
        voiceSelect.innerHTML = '<option value="">No hay voces disponibles</option>';
        return;
      }

      sortedVoices.forEach((voice, i) => {
        const option = document.createElement('option');
        option.value = i;
        option.textContent = `${voice.name} (${voice.lang})`;
        if (voice.lang.startsWith('es') && !selectedVoice) {
          option.selected = true;
          selectedVoice = voice;
        }
        voiceSelect.appendChild(option);
      });

      // Si no hay voz española, usar la primera
      if (!selectedVoice && sortedVoices.length > 0) {
        selectedVoice = sortedVoices[0];
        voiceSelect.selectedIndex = 0;
      }

      log("Voces cargadas: " + sortedVoices.length);
    }

    // Las voces pueden cargarse async
    if (synth.onvoiceschanged !== undefined) {
      synth.onvoiceschanged = loadVoices;
    }
    loadVoices();

    voiceSelect.addEventListener('change', () => {
      const allVoices = synth.getVoices();
      const spanishVoices = allVoices.filter(v => v.lang.startsWith('es'));
      const otherVoices = allVoices.filter(v => !v.lang.startsWith('es'));
      const sortedVoices = [...spanishVoices, ...otherVoices];
      selectedVoice = sortedVoices[voiceSelect.value] || null;
      log("Voz seleccionada: " + (selectedVoice?.name || "ninguna"));
    });

    function speak(text, audioId = null) {
      return new Promise(async (resolve) => {
        if (!text && !audioId) {
          resolve();
          return;
        }

        // 1) Buscar audio pregenerado por ID
        if (audioId && AUDIO_BANK[audioId]) {
          const entry = AUDIO_BANK[audioId];
          log("Audio pregenerado: " + audioId);
          bubbleEl.textContent = entry.text;
          try {
            await playPrerecordedAudio(entry.audio);
            resolve();
            return;
          } catch (e) {
            log("Error audio pregenerado: " + e.message);
          }
        }

        // 2) Buscar audio pregenerado por texto exacto
        if (text && AUDIO_BY_TEXT[text]) {
          log("Audio por texto encontrado");
          try {
            await playPrerecordedAudio(AUDIO_BY_TEXT[text]);
            resolve();
            return;
          } catch (e) {
            log("Error audio por texto: " + e.message);
          }
        }

        // 3) Si hay API key de ElevenLabs, usarla
        if (CONFIG.ELEVENLABS_API_KEY && text) {
          try {
            await speakWithElevenLabs(text);
            resolve();
            return;
          } catch (e) {
            log("ElevenLabs error: " + e.message);
            if (!CONFIG.USE_BROWSER_TTS_FALLBACK) {
              stopTalking();
              resolve();
              return;
            }
            log("Usando TTS del navegador como fallback");
          }
        }

        // 4) TTS del navegador como último recurso
        if (!synth || !text) {
          resolve();
          return;
        }

        synth.cancel();

        currentUtterance = new SpeechSynthesisUtterance(text);

        if (selectedVoice) {
          currentUtterance.voice = selectedVoice;
        }

        currentUtterance.lang = 'es-ES';
        currentUtterance.rate = 1.0;
        currentUtterance.pitch = 1.0;

        currentUtterance.onstart = () => {
          log("TTS navegador iniciado");
          startTTSLipSync();
        };

        currentUtterance.onend = () => {
          log("TTS navegador terminado");
          stopTalking();
          resolve();
        };

        currentUtterance.onerror = (e) => {
          log("TTS error: " + e.error);
          stopTalking();
          resolve();
        };

        synth.speak(currentUtterance);
      });
    }

    // -----------------------------
    // Audio Pregenerado
    // -----------------------------
    let prerecordedAudio = null;

    async function playPrerecordedAudio(audioUrl, textWithPauses = "") {
      return new Promise((resolve, reject) => {
        if (prerecordedAudio) {
          prerecordedAudio.pause();
          prerecordedAudio = null;
        }

        prerecordedAudio = new Audio(audioUrl);

        prerecordedAudio.onplay = () => {
          log("Audio pregenerado reproduciendo");
          // Usar lip-sync con pausas si hay texto con ::
          if (textWithPauses && textWithPauses.includes("::")) {
            startTTSLipSyncWithPauses(textWithPauses);
          } else {
            startTTSLipSync();
          }
        };

        prerecordedAudio.onended = () => {
          log("Audio pregenerado terminado");
          stopTalking();
          resolve();
        };

        prerecordedAudio.onerror = (e) => {
          log("Error cargando audio: " + audioUrl);
          stopTalking();
          reject(new Error("Error cargando audio pregenerado"));
        };

        prerecordedAudio.play().catch(reject);
      });
    }

    // -----------------------------
    // ElevenLabs TTS
    // -----------------------------
    let elevenLabsAudio = null;

    async function speakWithElevenLabs(text) {
      log("ElevenLabs: generando audio...");

      const response = await fetch(
        `https://api.elevenlabs.io/v1/text-to-speech/${CONFIG.ELEVENLABS_VOICE_ID}`,
        {
          method: "POST",
          headers: {
            "Accept": "audio/mpeg",
            "Content-Type": "application/json",
            "xi-api-key": CONFIG.ELEVENLABS_API_KEY,
          },
          body: JSON.stringify({
            text: text,
            model_id: CONFIG.ELEVENLABS_MODEL,
            voice_settings: {
              stability: 0.5,
              similarity_boost: 0.75,
            },
          }),
        }
      );

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`API error ${response.status}: ${errorText}`);
      }

      log("ElevenLabs: audio recibido");

      const audioBlob = await response.blob();
      const audioUrl = URL.createObjectURL(audioBlob);

      return new Promise((resolve, reject) => {
        if (elevenLabsAudio) {
          elevenLabsAudio.pause();
          elevenLabsAudio = null;
        }

        elevenLabsAudio = new Audio(audioUrl);

        elevenLabsAudio.onplay = () => {
          log("ElevenLabs: reproduciendo");
          startTTSLipSync();
        };

        elevenLabsAudio.onended = () => {
          log("ElevenLabs: terminado");
          stopTalking();
          URL.revokeObjectURL(audioUrl);
          resolve();
        };

        elevenLabsAudio.onerror = (e) => {
          log("ElevenLabs: error reproducción");
          stopTalking();
          URL.revokeObjectURL(audioUrl);
          reject(new Error("Error reproduciendo audio"));
        };

        elevenLabsAudio.play().catch(reject);
      });
    }

    function stopSpeaking() {
      if (synth) {
        synth.cancel();
      }
      if (elevenLabsAudio) {
        elevenLabsAudio.pause();
        elevenLabsAudio = null;
      }
      if (prerecordedAudio) {
        prerecordedAudio.pause();
        prerecordedAudio = null;
      }
      stopTalking();
    }

    // -----------------------------
    // RIVE
    // -----------------------------
    const RIVE_FILE = CONFIG.RIVE_FILE;
    const STATE_MACHINE = CONFIG.STATE_MACHINE;

    let riveInstance = null;
    let hasRive = false;
    let isTalkingInput = null;
    let visemeIDInput = null;
    let visemeTimer = null;
    let ttsLipSyncTimer = null;

    async function initRive() {
      log("Iniciando Rive...");
      setStatus("Cargando avatar...", "loading");

      const Rive = RiveCanvas.Rive || RiveCanvas.default || RiveCanvas;

      if (typeof Rive !== "function") {
        log("ERROR: No se encontró constructor Rive");
        fallbackToCSS("Constructor no encontrado");
        return;
      }

      try {
        riveInstance = new Rive({
          src: RIVE_FILE,
          canvas: riveCanvas,
          stateMachines: STATE_MACHINE,
          autoplay: true,
          onLoad: onRiveLoad,
          onLoadError: onRiveError
        });
      } catch (e) {
        log("Error creando Rive: " + e.message);
        fallbackToCSS(e.message);
      }
    }

    function onRiveLoad() {
      log("Asset cargado ✓");

      setTimeout(() => {
        try {
          const inputs = riveInstance.stateMachineInputs(STATE_MACHINE);

          if (!inputs || inputs.length === 0) {
            log("No se encontraron inputs");
            const sms = riveInstance.stateMachineNames;
            log("State Machines: " + JSON.stringify(sms));
            fallbackToCSS("Sin inputs");
            return;
          }

          log("Inputs: " + inputs.length);

          inputs.forEach(input => {
            log(`  → ${input.name}`);
            if (input.name === "isTalking") isTalkingInput = input;
            else if (input.name === "VisemeID") visemeIDInput = input;
          });

          if (isTalkingInput && visemeIDInput) {
            hasRive = true;
            riveWrap.style.display = "grid";
            cssAvatar.style.display = "none";
            setStatus("Avatar listo ✓", "ok");
            log("✓ Inputs conectados");
          } else {
            fallbackToCSS("Inputs incompletos");
          }

        } catch (e) {
          log("Error inputs: " + e.message);
          fallbackToCSS(e.message);
        }
      }, 100);
    }

    function onRiveError(err) {
      log("Error .riv: " + err);
      fallbackToCSS(String(err));
    }

    function fallbackToCSS(reason) {
      hasRive = false;
      riveWrap.style.display = "none";
      cssAvatar.style.display = "grid";
      setStatus("CSS fallback", "error");
    }

    // -----------------------------
    // Control de habla
    // -----------------------------
    function stopTalking() {
      if (visemeTimer) {
        clearInterval(visemeTimer);
        visemeTimer = null;
      }
      if (ttsLipSyncTimer) {
        clearInterval(ttsLipSyncTimer);
        ttsLipSyncTimer = null;
      }

      if (hasRive) {
        if (isTalkingInput) isTalkingInput.value = false;
        if (visemeIDInput) visemeIDInput.value = 0;
      }

      cssSetMouthOpen(0);
    }

    function startTalking(durationMs = 2000) {
      log("Animando " + durationMs + "ms");

      if (!hasRive) {
        startCSSFakeTalking(durationMs);
        return;
      }

      if (isTalkingInput) isTalkingInput.value = true;

      if (visemeIDInput) {
        if (visemeTimer) clearInterval(visemeTimer);

        const visemes = [0, 1, 2, 3, 4, 5, 6, 7, 8];
        let lastViseme = 0;

        visemeTimer = setInterval(() => {
          let newViseme;
          do {
            newViseme = visemes[Math.floor(Math.random() * visemes.length)];
          } while (newViseme === lastViseme);

          lastViseme = newViseme;
          visemeIDInput.value = newViseme;
        }, 100);
      }

      setTimeout(() => {
        stopTalking();
      }, durationMs);
    }

    // Lip-sync para TTS (sin análisis de audio, solo animación)
    // Soporta pausas con :: en el texto
    let currentSpeakingText = "";

    function startTTSLipSync() {
      if (!hasRive) {
        // CSS fallback con animación continua
        startCSSFakeTalking(99999);
        return;
      }

      if (isTalkingInput) isTalkingInput.value = true;

      if (visemeIDInput) {
        if (ttsLipSyncTimer) clearInterval(ttsLipSyncTimer);

        const visemes = [0, 1, 2, 3, 4, 5, 6, 7, 8];
        let lastViseme = 0;

        ttsLipSyncTimer = setInterval(() => {
          let newViseme;
          do {
            newViseme = visemes[Math.floor(Math.random() * visemes.length)];
          } while (newViseme === lastViseme);

          lastViseme = newViseme;
          visemeIDInput.value = newViseme;
        }, 90);
      }
    }

    // Lip-sync con pausas basadas en :: en el texto
    function startTTSLipSyncWithPauses(text) {
      if (!hasRive) {
        startCSSFakeTalking(99999);
        return;
      }

      // Dividir texto por :: para calcular pausas
      const segments = text.split("::");
      if (segments.length <= 1) {
        // No hay pausas, usar lip-sync normal
        startTTSLipSync();
        return;
      }

      log("Lip-sync con " + (segments.length - 1) + " pausas");

      // Calcular tiempos de pausa basados en posición del ::
      const totalLength = text.replace(/::/g, "").length;
      const pauseDuration = 500; // 0.5 segundos

      let isPaused = false;
      let charCount = 0;
      let pausePoints = [];

      // Calcular en qué momento (aprox) ocurre cada pausa
      for (let i = 0; i < segments.length - 1; i++) {
        charCount += segments[i].length;
        // Aproximar tiempo: ~50ms por carácter (ajustable)
        const timeMs = charCount * 50;
        pausePoints.push(timeMs);
      }

      if (isTalkingInput) isTalkingInput.value = true;

      if (visemeIDInput) {
        if (ttsLipSyncTimer) clearInterval(ttsLipSyncTimer);

        const visemes = [0, 1, 2, 3, 4, 5, 6, 7, 8];
        let lastViseme = 0;
        const startTime = performance.now();
        let currentPauseIndex = 0;
        let pauseEndTime = 0;

        ttsLipSyncTimer = setInterval(() => {
          const elapsed = performance.now() - startTime;

          // Verificar si estamos en una pausa
          if (currentPauseIndex < pausePoints.length) {
            const pauseStart = pausePoints[currentPauseIndex];

            if (elapsed >= pauseStart && elapsed < pauseStart + pauseDuration) {
              // Estamos en pausa - cerrar boca
              visemeIDInput.value = 0;
              if (isTalkingInput) isTalkingInput.value = false;
              return;
            } else if (elapsed >= pauseStart + pauseDuration) {
              // Pausa terminada, pasar a la siguiente
              currentPauseIndex++;
              if (isTalkingInput) isTalkingInput.value = true;
            }
          }

          // Animación normal
          let newViseme;
          do {
            newViseme = visemes[Math.floor(Math.random() * visemes.length)];
          } while (newViseme === lastViseme);

          lastViseme = newViseme;
          visemeIDInput.value = newViseme;
        }, 90);
      }
    }

    function startCSSFakeTalking(durationMs) {
      const start = performance.now();

      const tick = () => {
        const elapsed = performance.now() - start;
        const progress = elapsed / durationMs;

        if (progress >= 1) {
          cssSetMouthOpen(0);
          return;
        }

        const wave = Math.sin(elapsed / 85);
        const attack = Math.min(1, elapsed / 150);
        const decay = durationMs > 10000 ? 1 : (1 - Math.max(0, (progress - 0.85) / 0.15));
        const envelope = attack * decay;

        cssSetMouthOpen((0.45 + 0.55 * wave) * envelope);
        requestAnimationFrame(tick);
      };

      requestAnimationFrame(tick);
    }

    // -----------------------------
    // Control general
    // -----------------------------
    function setIdle() {
      stopSpeaking();
      bubbleEl.textContent = "En espera…";
    }

    $("idleBtn").onclick = () => {
      log("Idle");
      setIdle();
    };

    $("testTalk").onclick = async () => {
      // Probar con audio pregenerado "welcome" si existe
      if (AUDIO_BANK["welcome"]) {
        log("Test: audio pregenerado 'welcome'");
        await speak(null, "welcome");
      } else {
        // Fallback a texto normal
        const testText = "Hola, soy tu asistente virtual de Gespropiedad. ¿En qué puedo ayudarte hoy?";
        bubbleEl.textContent = testText;
        log("Test TTS");
        await speak(testText);
      }
    };

    // -----------------------------
    // WebSocket
    // -----------------------------
    const qp = new URLSearchParams(location.search);
    const BACKEND_HOST = qp.get("backend") || CONFIG.BACKEND_HOST;
    const wsProto = location.protocol === "https:" ? "wss://" : "ws://";
    let ws = null;
    let wsReconnectTimer = null;

    function connectWebSocket() {
      if (wsReconnectTimer) clearTimeout(wsReconnectTimer);

      try {
        log("WS: " + BACKEND_HOST);
        ws = new WebSocket(wsProto + BACKEND_HOST);

        ws.onopen = () => log("WS conectado ✓");

        ws.onclose = () => {
          log("WS cerrado");
          wsReconnectTimer = setTimeout(connectWebSocket, 5000);
        };

        ws.onerror = () => log("WS error");

        ws.onmessage = async (ev) => {
          let msg;
          try { msg = JSON.parse(ev.data); } catch { return; }

          log("WS: " + msg.type);

          if (msg.type === "bot_speaking_start") {
            const rawText = msg.text || "";
            const audioId = msg.audioId || msg.lineId || null;

            // Limpiar :: del texto para mostrar en bubble
            const cleanText = rawText.replace(/::/g, " ").replace(/\s+/g, " ").trim();
            if (cleanText) bubbleEl.textContent = cleanText;

            // 1) Si viene audioUrl del backend, usarla directamente
            if (msg.audioUrl) {
              log("Reproduciendo audioUrl: " + msg.audioUrl);
              try {
                // Pasar texto original con :: para las pausas
                await playPrerecordedAudio(msg.audioUrl, rawText);
              } catch (e) {
                log("Error audioUrl: " + e.message);
                await speak(cleanText, audioId);
              }
            }
            // 2) Si no hay audioUrl, usar sistema de prioridad local
            else {
              await speak(cleanText, audioId);
            }
          }

          if (msg.type === "bot_speaking_end") {
            stopSpeaking();
          }
        };
      } catch (e) {
        log("WS error: " + e.message);
        wsReconnectTimer = setTimeout(connectWebSocket, 5000);
      }
    }

    // -----------------------------
    // Init
    // -----------------------------
    log("Iniciando...");
    if (CONFIG.ELEVENLABS_API_KEY) {
      log("TTS: ElevenLabs configurado");
    } else {
      log("TTS: Navegador (sin API key)");
    }

    // -----------------------------
    // Audio unlock - Requiere interacción del usuario
    // -----------------------------
    let audioUnlocked = false;
    const startOverlay = $("startOverlay");
    const startBtn = $("startBtn");

    async function unlockAudio() {
      try {
        // Crear y reproducir audio silencioso para desbloquear
        const silentAudio = new Audio("data:audio/wav;base64,UklGRnoGAABXQVZFZm10IBAAAAABAAEAQB8AAEAfAAABAAgAZGF0YQoGAACBhYqFbF1fdJivrJBhNjVgodDbq2EcBj+a2teleCAHQJnx+aCFNgRDmvz/mXoxBEaZ/P+YdywFR5r8/5d3KgZIm/z/lnkpB0mc/P+VeigISp38/5R7JwlLnfz/k3wmCkye/P+SfSULTZ/8/5F+JAxOoPz/kH8jDU+h/P+PgCIOUKL8/46BIQ9Ro/z/jYIfEFKk/P+MgyAQU6X8/4uEHxFUpvz/ioUeElWn/P+Jhh0TV6j8/4iHHBRYqfz/h4gcFVqq/P+GiRsWW6v8/4WKGhdcrPz/hIoZGF2t/P+DixgZXq78/4KMGB5fr/z/gY0XH2Cw/P+AjhYgYbH8/3+PFSFisfz/fpAUI2Oz/P99kRMkZLT8/3ySEiVltfz/e5MSJGW1");
        silentAudio.volume = 0.01;
        await silentAudio.play();
        silentAudio.pause();

        // También preparar Web Speech API
        if (synth) {
          const testUtterance = new SpeechSynthesisUtterance("");
          testUtterance.volume = 0;
          synth.speak(testUtterance);
          synth.cancel();
        }

        audioUnlocked = true;
        log("Audio desbloqueado ✓");
        return true;
      } catch (e) {
        log("Error desbloqueando audio: " + e.message);
        return false;
      }
    }

    startBtn.onclick = async () => {
      await unlockAudio();
      startOverlay.classList.add("hidden");
    };

    // También desbloquear con clic en cualquier parte del overlay
    startOverlay.onclick = async (e) => {
      if (e.target === startOverlay) {
        await unlockAudio();
        startOverlay.classList.add("hidden");
      }
    };

    // Fullscreen toggle
    const fullscreenBtn = $("fullscreenBtn");
    let isFullscreen = false;

    fullscreenBtn.onclick = () => {
      isFullscreen = !isFullscreen;

      if (isFullscreen) {
        riveWrap.classList.add("fullscreen");
        fullscreenBtn.innerHTML = '<i data-lucide="minimize-2"></i>';
        lucide.createIcons();
        fullscreenBtn.title = "Salir de pantalla completa";

        // También intentar fullscreen nativo
        if (riveWrap.requestFullscreen) {
          riveWrap.requestFullscreen().catch(() => { });
        }
      } else {
        riveWrap.classList.remove("fullscreen");
        fullscreenBtn.innerHTML = '<i data-lucide="maximize-2"></i>';
        lucide.createIcons();
        fullscreenBtn.title = "Pantalla completa";

        if (document.exitFullscreen && document.fullscreenElement) {
          document.exitFullscreen().catch(() => { });
        }
      }
    };

    // Salir de fullscreen con ESC o cuando sale del fullscreen nativo
    document.addEventListener("fullscreenchange", () => {
      if (!document.fullscreenElement && isFullscreen) {
        isFullscreen = false;
        riveWrap.classList.remove("fullscreen");
        fullscreenBtn.innerHTML = '<i data-lucide="maximize-2"></i>';
        lucide.createIcons();
        fullscreenBtn.title = "Pantalla completa";
      }
    });

    document.addEventListener("keydown", (e) => {
      if (e.key === "Escape" && isFullscreen) {
        isFullscreen = false;
        riveWrap.classList.remove("fullscreen");
        fullscreenBtn.innerHTML = '<i data-lucide="maximize-2"></i>';
        lucide.createIcons();
        fullscreenBtn.title = "Pantalla completa";
      }
    });

    await initRive();
    connectWebSocket();
    setIdle();

    // Inicializar iconos Lucide
    lucide.createIcons();
  </script>
</body>

</html>